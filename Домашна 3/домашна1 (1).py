# -*- coding: utf-8 -*-
"""Домашна1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fF9trgGdp5h_SlRmvqdULkBSFGeNLFzG
"""

import requests
import pandas as pd
from datetime import datetime, timedelta
from tqdm import tqdm
import time
from google.colab import files

start_date = datetime(2014, 1, 1)
end_date = datetime(2024, 10, 31)

data_frames = []

session = requests.Session()

current_date = start_date
date_range = (end_date - start_date).days + 1

for _ in tqdm(range(date_range), desc="Downloading data"):
    date_str = current_date.strftime('%Y-%m-%d')

    url = f"https://www.mse.mk/daily/stats/symbolhistory/REPL?date={date_str}"


    for attempt in range(3):
        try:
            response = session.get(url, timeout=10)
            if response.status_code == 200:
                df = pd.read_html(response.content)[0]
                data_frames.append(df)
                print(f"Data for {date_str} downloaded successfully.")
                break
            else:
                print(f"Failed to download data for {date_str}. Status code: {response.status_code}")
        except Exception as e:
            print(f"Error downloading data for {date_str}: {e}")
            time.sleep(1)
    else:
        print(f"Failed to download data for {date_str} after 3 attempts.")


    current_date += timedelta(days=1)


if data_frames:
    all_data = pd.concat(data_frames, ignore_index=True)
    csv_file_path = "/content/historical_data.csv"
    all_data.to_csv(csv_file_path, index=False)
    print("Data saved to historical_data.csv")


    files.download(csv_file_path)
else:
    print("No data downloaded.")

import requests
from bs4 import BeautifulSoup
import re

url = 'https://www.mse.mk/daily/stats/symbolhistory/REPL'
response = requests.get(url)
soup = BeautifulSoup(response.text, 'html.parser')


publishers = []
for option in soup.select('select#publisher-dropdown option'):
    code = option.get('value')

    if re.match("^[A-Za-z]+$", code):
        publishers.append(code)

import pandas as pd

data_path = '/content/historical_data.csv'
data = pd.read_csv(data_path)


last_dates = data.groupby('publisher_code')['date'].max().to_dict()

from datetime import datetime, timedelta


end_date = datetime.today()
start_date = end_date - timedelta(days=365 * 10)


for publisher in publishers:
    last_date = last_dates.get(publisher, start_date)
    print(f"Publisher: {publisher}, Last Date: {last_date}")

print(data.columns)

print(data.head())

import pandas as pd
from datetime import datetime, timedelta

data_path = '/content/historical_data.csv'
data = pd.read_csv(data_path)


data['Date'] = pd.to_datetime(data['Date'], errors='coerce')


last_date = data['Date'].max()
print(f"Last available date in the dataset: {last_date}")


end_date = datetime.today()
start_date = end_date - timedelta(days=365 * 10)


if last_date >= start_date:
    print("Data contains entries within the last 10 years.")
else:
    print("No data from the last 10 years.")

def fetch_data(publisher, start_date, end_date):

    return pd.DataFrame()


for publisher, last_date in last_dates.items():
    new_data = fetch_data(publisher, last_date, end_date)
    data = pd.concat([data, new_data])


data.to_csv(data_path, index=False)


data['date'] = pd.to_datetime(data['date']).dt.strftime('%d-%m-%Y')


data['price'] = data['price'].apply(lambda x: f"{x:,.2f}")

for publisher, last_date in last_dates.items():
    new_data = fetch_data(publisher, last_date, end_date)
    data = pd.concat([data, new_data], ignore_index=True)


data.to_csv(data_path, index=False)


data['Date'] = pd.to_datetime(data['Date']).dt.strftime('%d-%m-%Y')


if 'Last trade price' in data.columns:
    data['Last trade price'] = data['Last trade price'].apply(lambda x: f"{x:,.2f}")

import pandas as pd
from datetime import datetime, timedelta


data_path = '/content/historical_data.csv'
data = pd.read_csv(data_path)


last_dates = data.groupby('publisher_code')['Date'].max().to_dict()


end_date = datetime.today()
start_date = end_date - timedelta(days=365 * 10)


def fetch_data(publisher, start_date, end_date):

    return pd.DataFrame()

for publisher, last_date in last_dates.items():
    new_data = fetch_data(publisher, last_date, end_date)
    data = pd.concat([data, new_data], ignore_index=True)

data.to_csv(data_path, index=False)


data['Date'] = pd.to_datetime(data['Date']).dt.strftime('%Y-%m-%d')


if 'Last trade price' in data.columns:
    data['Last trade price'] = data['Last trade price'].apply(lambda x: f"{x:,.2f}")

print("Updated data with new entries and formatted columns:")
print(data.head())

last_dates = data.groupby('publisher_code')['Date'].max().to_dict()

import requests
import pandas as pd
from datetime import datetime, timedelta
from tqdm import tqdm
import time
from google.colab import files
data_path = '/content/historical_data.csv'
data = pd.read_csv(data_path)

data['Date'] = pd.to_datetime(data['Date'], errors='coerce')

last_dates = data.groupby('Publisher')['Date'].max().to_dict()


end_date = datetime.today()
date_range = (end_date - last_dates['REPL']).days + 1


def fetch_missing_data(publisher, start_date, end_date):
    data_frames = []
    current_date = start_date
    while current_date <= end_date:
        date_str = current_date.strftime('%Y-%m-%d')
        url = f"https://www.mse.mk/daily/stats/symbolhistory/{publisher}?date={date_str}"

        for attempt in range(3):
            try:
                response = requests.get(url, timeout=10)
                if response.status_code == 200:

                    df = pd.read_html(response.content)[0]
                    df['Publisher'] = publisher
                    data_frames.append(df)
                    print(f"Data for {publisher} on {date_str} fetched successfully.")
                    break
                else:
                    print(f"Failed to fetch data for {publisher} on {date_str}. Status: {response.status_code}")
            except Exception as e:
                print(f"Error fetching data for {publisher} on {date_str}: {e}")
                time.sleep(1)

        current_date += timedelta(days=1)
    return pd.concat(data_frames, ignore_index=True)


all_new_data = []
for publisher, last_date in last_dates.items():
    if last_date < end_date:
        new_data = fetch_missing_data(publisher, last_date + timedelta(days=1), end_date)
        all_new_data.append(new_data)

if all_new_data:
    new_data_combined = pd.concat(all_new_data, ignore_index=True)

    data = pd.concat([data, new_data_combined], ignore_index=True)

    data = data.sort_values(by='Date').reset_index(drop=True)
    data.to_csv(data_path, index=False)

    print("Missing data successfully fetched and merged.")
else:
    print("No missing data found.")


files.download(data_path)

print(data.columns)
print(data.head())

import pandas as pd
import requests
from datetime import datetime, timedelta
from google.colab import files


data_path = '/content/historical_data.csv'
data = pd.read_csv(data_path)


data['Date'] = pd.to_datetime(data['Date'], errors='coerce')


start_date_10_years = datetime(2014, 10, 28)
end_date_10_years = datetime(2024, 10, 28)

start_date_recent = datetime(2024, 10, 28)
end_date_recent = datetime(2024, 11, 9)


def fetch_data(date):

    url = f"https://www.mse.mk/daily/stats/symbolhistory/REPL?date={date.strftime('%Y-%m-%d')}"
    response = requests.get(url)
    if response.status_code == 200:

        df = pd.read_html(response.content)[0]
        df['Date'] = date
        return df
    else:
        print(f"Failed to fetch data for {date}")
        return pd.DataFrame()

missing_dates_10_years = pd.date_range(start_date_10_years, end_date_10_years)

new_data_10_years = pd.DataFrame()
for date in missing_dates_10_years:
    data_for_date = fetch_data(date)
    new_data_10_years = pd.concat([new_data_10_years, data_for_date], ignore_index=True)

missing_dates_recent = pd.date_range(start_date_recent, end_date_recent)

new_data_recent = pd.DataFrame()
for date in missing_dates_recent:
    data_for_date = fetch_data(date)
    new_data_recent = pd.concat([new_data_recent, data_for_date], ignore_index=True)

all_data = pd.concat([data, new_data_10_years, new_data_recent], ignore_index=True).sort_values(by='Date')

all_data.to_csv(data_path, index=False)

files.download(data_path)

print("Missing data fetched and merged successfully.")

from datetime import datetime

start_date = datetime(2014, 1, 1)
end_date = datetime(2024, 10, 31)

current_date = start_date
while current_date <= end_date:
    month_end = current_date.replace(day=28) + timedelta(days=4)
    month_end = month_end - timedelta(days=month_end.day)

    url = f'https://www.mse.mk/daily/stats/symbolhistory/REPL?date={current_date.strftime("%Y-%m-%d")}'
    response = requests.get(url, timeout=30)

    if response.status_code == 200:
        print(f"Fetched data for {current_date.strftime('%Y-%m-%d')}")
    else:
        print(f"Failed to fetch data for {current_date.strftime('%Y-%m-%d')}")


    current_date = month_end + timedelta(days=1)

import requests
from datetime import datetime, timedelta
import pandas as pd

start_date = datetime(2014, 1, 1)
end_date = datetime(2024, 10, 31)

current_date = start_date
all_data = []

while current_date <= end_date:
    month_end = current_date.replace(day=28) + timedelta(days=4)
    month_end = month_end - timedelta(days=month_end.day)

    url = f'https://www.mse.mk/daily/stats/symbolhistory/REPL?date={current_date.strftime("%Y-%m-%d")}'
    response = requests.get(url, timeout=30)

    if response.status_code == 200:
        print(f"Fetched data for {current_date.strftime('%Y-%m-%d')}")

        try:
            df = pd.read_html(response.content)[0]
            all_data.append(df)
        except Exception as e:
            print(f"Error processing data for {current_date.strftime('%Y-%m-%d')}: {e}")
    else:
        print(f"Failed to fetch data for {current_date.strftime('%Y-%m-%d')}")


    current_date = month_end + timedelta(days=1)

if all_data:
    merged_data = pd.concat(all_data, ignore_index=True)
    merged_data.to_csv('mse_data.csv', index=False)
    print("Data saved to mse_data.csv")
else:
    print("No data was fetched.")

from google.colab import files
files.download('mse_data.csv')

import requests
from datetime import datetime, timedelta
import pandas as pd

start_date = datetime(2014, 10, 28)
end_date = datetime(2024, 10, 28)

current_date = start_date
all_data = []

while current_date <= end_date:
    month_end = current_date.replace(day=28) + timedelta(days=4)
    month_end = month_end - timedelta(days=month_end.day)

    url = f'https://www.mse.mk/daily/stats/symbolhistory/REPL?date={current_date.strftime("%Y-%m-%d")}'
    response = requests.get(url, timeout=30)

    if response.status_code == 200:
        print(f"Fetched data for {current_date.strftime('%Y-%m-%d')}")
        try:
            df = pd.read_html(response.content)[0]

            if 'Date' in df.columns:
                df['Date'] = df['Date'].apply(lambda x: x if x != '####' else None)

            if not df.empty:
                all_data.append(df)
            else:
                print(f"No data for {current_date.strftime('%Y-%m-%d')}")
        except Exception as e:
            print(f"Error processing data for {current_date.strftime('%Y-%m-%d')}: {e}")
    else:
        print(f"Failed to fetch data for {current_date.strftime('%Y-%m-%d')}")

    current_date = month_end + timedelta(days=1)

if all_data:
    merged_data = pd.concat(all_data, ignore_index=True)

    merged_data = merged_data.fillna('Missing')

    merged_data.to_csv('mse_data1.csv', index=False)
    print("Data saved to mse_data1.csv")
else:
    print("No data was fetched.")

from google.colab import files
files.download('mse_data1.csv')

import requests
from datetime import datetime, timedelta
import pandas as pd


start_date = datetime(2014, 1, 1)
end_date = datetime(2024, 10, 31)

current_date = start_date
all_data = []

while current_date <= end_date:
    month_end = current_date.replace(day=28) + timedelta(days=4)
    month_end = month_end - timedelta(days=month_end.day)

    url = f'https://www.mse.mk/daily/stats/symbolhistory/REPL?date={current_date.strftime("%Y-%m-%d")}'
    response = requests.get(url, timeout=30)

    if response.status_code == 200:
        print(f"Fetched data for {current_date.strftime('%Y-%m-%d')}")
        try:
            df = pd.read_html(response.content)[0]

            df = df.applymap(lambda x: None if x == '####' else x)

            df = df.dropna(axis=1, how='any')

            df = df.dropna(how='all')

            if not df.empty:
                all_data.append(df)
            else:
                print(f"No valid data for {current_date.strftime('%Y-%m-%d')}")
        except Exception as e:
            print(f"Error processing data for {current_date.strftime('%Y-%m-%d')}: {e}")
    else:
        print(f"Failed to fetch data for {current_date.strftime('%Y-%m-%d')}")

    current_date = month_end + timedelta(days=1)

if all_data:
    merged_data = pd.concat(all_data, ignore_index=True)

    merged_data.to_csv('mse_data_cleaned_full.csv', index=False)
    print("Data saved to mse_data_cleaned_full.csv")
else:
    print("No data was fetched.")

from google.colab import files
files.download('mse_data_cleaned_full.csv')

import requests
from datetime import datetime, timedelta
import pandas as pd

start_date = datetime(2014, 1, 1)
end_date = datetime(2024, 10, 31)

current_date = start_date
all_data = []

while current_date <= end_date:
    month_end = current_date.replace(day=28) + timedelta(days=4)
    month_end = month_end - timedelta(days=month_end.day)

    url = f'https://www.mse.mk/daily/stats/symbolhistory/REPL?date={current_date.strftime("%Y-%m-%d")}'
    response = requests.get(url, timeout=30)

    if response.status_code == 200:
        print(f"Fetched data for {current_date.strftime('%Y-%m-%d')}")
        try:
            df = pd.read_html(response.content)[0]

            df = df.applymap(lambda x: None if x == '####' else x)

            df = df.dropna(axis=1, how='all')
            df = df.loc[:, (df != 0).any(axis=0)]


            df = df.dropna(how='all')


            df = df[~(df == 0).any(axis=1)]

            if not df.empty:
                all_data.append(df)
            else:
                print(f"No valid data for {current_date.strftime('%Y-%m-%d')}")
        except Exception as e:
            print(f"Error processing data for {current_date.strftime('%Y-%m-%d')}: {e}")
    else:
        print(f"Failed to fetch data for {current_date.strftime('%Y-%m-%d')}")


    current_date = month_end + timedelta(days=1)


if all_data:
    merged_data = pd.concat(all_data, ignore_index=True)


    merged_data.to_csv('mse_data_cleaned_no_zeros_and_invalid_columns.csv', index=False)
    print("Data saved to mse_data_cleaned_no_zeros_and_invalid_columns.csv")
else:
    print("No data was fetched.")

from google.colab import files
files.download('mse_data_cleaned_no_zeros_and_invalid_columns.csv')

import requests
from datetime import datetime, timedelta
import pandas as pd


start_date = datetime(2014, 1, 1)
end_date = datetime(2024, 10, 31)

current_date = start_date
all_data = []

while current_date <= end_date:
    month_end = current_date.replace(day=28) + timedelta(days=4)
    month_end = month_end - timedelta(days=month_end.day)

    url = f'https://www.mse.mk/daily/stats/symbolhistory/REPL?date={current_date.strftime("%Y-%m-%d")}'
    response = requests.get(url, timeout=30)


    if response.status_code == 200:
        print(f"Fetched data for {current_date.strftime('%Y-%m-%d')}")
        try:
            df = pd.read_html(response.content)[0]

            df = df.applymap(lambda x: None if x == '####' else x)

            df = df.dropna(axis=1, how='all')
            df = df.loc[:, (df != 0).any(axis=0)]
            df = df.loc[:, (df >= 0).any(axis=0)]

            df = df[~(df == 0).any(axis=1)]
            df = df[~(df < 0).any(axis=1)]
            df = df.dropna(how='all')
            df = df[~df.applymap(lambda x: isinstance(x, str)).any(axis=1)]

            if not df.empty:
                all_data.append(df)
            else:
                print(f"No valid data for {current_date.strftime('%Y-%m-%d')}")
        except Exception as e:
            print(f"Error processing data for {current_date.strftime('%Y-%m-%d')}: {e}")
    else:
        print(f"Failed to fetch data for {current_date.strftime('%Y-%m-%d')}")

    current_date = month_end + timedelta(days=1)

if all_data:
    merged_data = pd.concat(all_data, ignore_index=True)


    merged_data.to_csv('mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv', index=False)
    print("Data saved to mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv")
else:
    print("No data was fetched.")

import requests
from datetime import datetime, timedelta
import pandas as pd


start_date = datetime(2014, 1, 1)
end_date = datetime(2024, 10, 31)

current_date = start_date
all_data = []

while current_date <= end_date:
    month_end = current_date.replace(day=28) + timedelta(days=4)
    month_end = month_end - timedelta(days=month_end.day)

    url = f'https://www.mse.mk/daily/stats/symbolhistory/REPL?date={current_date.strftime("%Y-%m-%d")}'
    response = requests.get(url, timeout=30)


    if response.status_code == 200:
        print(f"Fetched data for {current_date.strftime('%Y-%m-%d')}")
        try:
            df = pd.read_html(response.content)[0]

            df = df.applymap(lambda x: None if x == '####' else x)

            df = df.apply(pd.to_numeric, errors='coerce')

            df = df.dropna(axis=1, how='all')
            df = df.loc[:, (df != 0).any(axis=0)]
            df = df.loc[:, (df >= 0).any(axis=0)]

            df = df[~(df == 0).any(axis=1)]
            df = df[~(df < 0).any(axis=1)]
            df = df.dropna(how='all')

            if not df.empty:
                all_data.append(df)
            else:
                print(f"No valid data for {current_date.strftime('%Y-%m-%d')}")
        except Exception as e:
            print(f"Error processing data for {current_date.strftime('%Y-%m-%d')}: {e}")
    else:
        print(f"Failed to fetch data for {current_date.strftime('%Y-%m-%d')}")

    current_date = month_end + timedelta(days=1)

if all_data:
    merged_data = pd.concat(all_data, ignore_index=True)

    merged_data.to_csv('mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv', index=False)
    print("Data saved to mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv")
else:
    print("No data was fetched.")

from google.colab import files
files.download('mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv')

!git clone https://github.com/jovana-angjelkovska/DIANS.git

!pip install pandas requests sqlalchemy sqlite3

!git config --global user.name "jovana-angjelkovska"
!git config --global user.email "jovana.angjelkovska@students.finki.ukim.mk"


!git add .


!git commit -m


!git push origin main

from google.colab import auth
auth.authenticate_user()

!git config --global user.name "jovana-angjelkovska"
!git config --global user.email "jovana.angjelkovska@students.finki.ukim.mk"

!git clone https://github.com/jovana-angjelkovska/DIANS.git

import shutil


shutil.copy('/content/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv', '/content/https://github.com/jovana-angjelkovska/DIANS.git')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/DIANS

!git add mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv

!git commit -m "Added cleaned data file"

!git push origin main

import pandas as pd

data = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv')

print(data.head())

print(data.info())

print(data.describe())

data['Date'] = pd.to_datetime(data['Date'])

print(data.columns)

data.rename(columns={'timestamp': 'Date'}, inplace=True)

data['Date'] = pd.to_datetime(data['Date'])

import pandas as pd

data['Date'] = pd.date_range(start='2022-01-01', periods=len(data), freq='D')

data['Date'] = pd.to_datetime(data['Date'])

data = data.sort_values(by='Date')

# Simple Moving Average (SMA)
data['SMA_20'] = data['Close'].rolling(window=20).mean()

# Exponential Moving Average (EMA)
data['EMA_20'] = data['Close'].ewm(span=20, adjust=False).mean()

def calculate_moving_averages(data, periods):
    for period in periods:
        data[f'SMA_{period}'] = data['close'].rolling(window=period).mean()
        data[f'EMA_{period}'] = data['close'].ewm(span=period, adjust=False).mean()
    return data

data = calculate_moving_averages(data, periods=[10, 20, 50])

print(data.columns)

data['SMA_20'] = data['Last trade price'].rolling(window=20).mean()

data['EMA_20'] = data['Last trade price'].ewm(span=20, adjust=False).mean()

pip install ta

from ta.momentum import RSIIndicator
import matplotlib.pyplot as plt

rsi = RSIIndicator(close=data['Last trade price'], window=14)
data['RSI'] = rsi.rsi()

plt.figure(figsize=(14, 7))
plt.plot(data['Date'], data['Last trade price'], label='Close Price', color='blue')
plt.plot(data['Date'], data['SMA_20'], label='SMA (20)', color='red')
plt.plot(data['Date'], data['EMA_20'], label='EMA (20)', color='green')
plt.legend()
plt.show()

plt.figure(figsize=(14, 7))
plt.plot(data['Date'], data['Last trade price'], label='Last Trade Price', color='blue')
plt.plot(data['Date'], data['SMA_20'], label='SMA (20)', color='red')

plt.scatter(data[data['Buy_Signal']]['Date'], data[data['Buy_Signal']]['Last trade price'], marker='^', color='green', label='Buy Signal', alpha=1)

plt.scatter(data[data['Sell_Signal']]['Date'], data[data['Sell_Signal']]['Last trade price'], marker='v', color='red', label='Sell Signal', alpha=1)

plt.legend()
plt.show()

data['Buy_Signal'] = (data['Last trade price'] > data['SMA_20']) & (data['Last trade price'].shift(1) <= data['SMA_20'].shift(1))

data['Sell_Signal'] = (data['Last trade price'] < data['SMA_20']) & (data['Last trade price'].shift(1) >= data['SMA_20'].shift(1))

print(data.columns)

import matplotlib.pyplot as plt

plt.figure(figsize=(14, 7))
plt.plot(data['Date'], data['Last trade price'], label='Last Trade Price', color='blue')
plt.plot(data['Date'], data['SMA_20'], label='SMA (20)', color='red')
plt.plot(data['Date'], data['EMA_20'], label='EMA (20)', color='green')

plt.scatter(data[data['Buy_Signal']].Date, data[data['Buy_Signal']].['Last trade price'], marker='^', color='green', label='Buy Signal', alpha=1)
plt.scatter(data[data['Sell_Signal']].Date, data[data['Sell_Signal']].['Last trade price'], marker='v', color='red', label='Sell Signal', alpha=1)

plt.xlabel('Date')
plt.ylabel('Price (in Denars)')
plt.title('Buy and Sell Signals with SMA/EMA')
plt.legend()

plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(14, 7))
plt.plot(data['Date'], data['Last trade price'], label='Last Trade Price', color='blue')
plt.plot(data['Date'], data['SMA_20'], label='SMA (20)', color='red')
plt.plot(data['Date'], data['EMA_20'], label='EMA (20)', color='green')

plt.scatter(data[data['Buy_Signal']].Date, data[data['Buy_Signal']]['Last trade price'], marker='^', color='green', label='Buy Signal', alpha=1)
plt.scatter(data[data['Sell_Signal']].Date, data[data['Sell_Signal']]['Last trade price'], marker='v', color='red', label='Sell Signal', alpha=1)

plt.xlabel('Date')
plt.ylabel('Price (in Denars)')
plt.title('Buy and Sell Signals with SMA/EMA')
plt.legend()

plt.show()

pip install pandas numpy ta matplotlib

import pandas as pd
import numpy as np
import ta
import matplotlib.pyplot as plt

data = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv', parse_dates=['Date'])

data['SMA_20'] = data['Last trade price'].rolling(window=20).mean()
data['EMA_20'] = data['Last trade price'].ewm(span=20, adjust=False).mean()

data['RSI'] = ta.momentum.RSIIndicator(data['Last trade price'], window=14).rsi()

data['MACD'] = ta.trend.MACD(data['Last trade price']).macd()
data['MACD_signal'] = ta.trend.MACD(data['Last trade price']).macd_signal()

data['Buy_Signal'] = np.where(data['Last trade price'] > data['SMA_20'], 1, 0)
data['Sell_Signal'] = np.where(data['Last trade price'] < data['SMA_20'], 1, 0)

plt.figure(figsize=(10, 6))
plt.plot(data['Date'], data['Last trade price'], label='Price', color='black')
plt.plot(data['Date'], data['SMA_20'], label='SMA 20', color='blue')
plt.plot(data['Date'], data['EMA_20'], label='EMA 20', color='red')

plt.scatter(data[data['Buy_Signal'] == 1].Date,
            data[data['Buy_Signal'] == 1]['Last trade price'],
            marker='^', color='green', label='Buy Signal', alpha=1)

plt.scatter(data[data['Sell_Signal'] == 1].Date,
            data[data['Sell_Signal'] == 1]['Last trade price'],
            marker='v', color='red', label='Sell Signal', alpha=1)

plt.legend()
plt.title('Stock Price with Buy/Sell Signals')
plt.xlabel('Date')
plt.ylabel('Price')
plt.show()

data = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv')
print(data.columns)

data = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv', parse_dates=['Trade Date'])

data = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv', parse_dates=['DateColumn'])

import pandas as pd

data = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv')

data['Date'] = pd.date_range(start='2022-01-01', periods=len(data), freq='D')

print(data.head())

import pandas as pd

data = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv')

data['Date'] = pd.to_datetime(data['Date'])

print(data.head())

data.columns = data.columns.str.strip()

print(data.columns)

import pandas as pd

date_range = pd.date_range(start='2022-01-01', periods=len(data), freq='D')

data['Date'] = date_range

print(data.head())

print(data.head())

from textblob import TextBlob
import requests

def get_news_from_api():
    return ["The company is doing great!", "The stock price fell due to bad earnings", "The company announced a new product"]

def analyze_sentiment(news_list):
    sentiment_results = []
    for article in news_list:
        blob = TextBlob(article)
        sentiment = blob.sentiment.polarity
        sentiment_results.append(sentiment)
    return sentiment_results

news_articles = get_news_from_api()
sentiments = analyze_sentiment(news_articles)

for news, sentiment in zip(news_articles, sentiments):
    recommendation = "Buy" if sentiment > 0 else "Sell"
    print(f"News: {news} | Sentiment: {sentiment:.2f} | Recommendation: {recommendation}")

import pandas as pd
import numpy as np
import ta
import matplotlib.pyplot as plt

data = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv', parse_dates=['Date'])

data['SMA_20'] = data['Last trade price'].rolling(window=20).mean()
data['EMA_20'] = data['Last trade price'].ewm(span=20, adjust=False).mean()

data['RSI'] = ta.momentum.RSIIndicator(data['Last trade price'], window=14).rsi()

data['MACD'] = ta.trend.MACD(data['Last trade price']).macd()
data['MACD_signal'] = ta.trend.MACD(data['Last trade price']).macd_signal()

data['Buy_Signal'] = np.where(data['Last trade price'] > data['SMA_20'], 1, 0)
data['Sell_Signal'] = np.where(data['Last trade price'] < data['SMA_20'], 1, 0)

plt.figure(figsize=(10, 6))
plt.plot(data['Date'], data['Last trade price'], label='Price', color='black')
plt.plot(data['Date'], data['SMA_20'], label='SMA 20', color='blue')
plt.plot(data['Date'], data['EMA_20'], label='EMA 20', color='red')

plt.scatter(data[data['Buy_Signal'] == 1].Date,
            data[data['Buy_Signal'] == 1]['Last trade price'],
            marker='^', color='green', label='Buy Signal', alpha=1)

plt.scatter(data[data['Sell_Signal'] == 1].Date,
            data[data['Sell_Signal'] == 1]['Last trade price'],
            marker='v', color='red', label='Sell Signal', alpha=1)

plt.legend()
plt.title('Stock Price with Buy/Sell Signals')
plt.xlabel('Date')
plt.ylabel('Price')
plt.show()

print(data.columns)

data['Date'] = pd.to_datetime(data['Date'])

print(data.dtypes)

data['SMA_20'] = data['Last trade price'].rolling(window=20).mean()
data['EMA_20'] = data['Last trade price'].ewm(span=20, adjust=False).mean()

print(data[['SMA_20', 'EMA_20']].isnull().sum())

data['RSI'] = ta.momentum.RSIIndicator(data['Last trade price'], window=14).rsi()

data['MACD'] = ta.trend.MACD(data['Last trade price']).macd()
data['MACD_signal'] = ta.trend.MACD(data['Last trade price']).macd_signal()

print(data[['RSI', 'MACD', 'MACD_signal']].isnull().sum())

data.dropna(subset=['RSI', 'MACD', 'MACD_signal'], inplace=True)

print(data[['RSI', 'MACD', 'MACD_signal']].isnull().sum())

data['RSI'].fillna(method='ffill', inplace=True)
data['MACD'].fillna(method='ffill', inplace=True)
data['MACD_signal'].fillna(method='ffill', inplace=True)

print(data[['RSI', 'MACD', 'MACD_signal']].isnull().sum())

data['RSI'] = data['RSI'].ffill()
data['MACD'] = data['MACD'].ffill()
data['MACD_signal'] = data['MACD_signal'].ffill()

print(data[['RSI', 'MACD', 'MACD_signal']].isnull().sum())

import pandas as pd
import numpy as np
import ta
import matplotlib.pyplot as plt

data = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv', parse_dates=['Date'])

data['SMA_20'] = data['Last trade price'].rolling(window=20).mean()
data['EMA_20'] = data['Last trade price'].ewm(span=20, adjust=False).mean()

data['RSI'] = ta.momentum.RSIIndicator(data['Last trade price'], window=14).rsi()

data['MACD'] = ta.trend.MACD(data['Last trade price']).macd()
data['MACD_signal'] = ta.trend.MACD(data['Last trade price']).macd_signal()

data['RSI'] = data['RSI'].ffill()
data['MACD'] = data['MACD'].ffill()
data['MACD_signal'] = data['MACD_signal'].ffill()

data['Buy_Signal'] = np.where(data['Last trade price'] > data['SMA_20'], 1, 0)
data['Sell_Signal'] = np.where(data['Last trade price'] < data['SMA_20'], 1, 0)

plt.figure(figsize=(10, 6))
plt.plot(data['Date'], data['Last trade price'], label='Price', color='black')
plt.plot(data['Date'], data['SMA_20'], label='SMA 20', color='blue')
plt.plot(data['Date'], data['EMA_20'], label='EMA 20', color='red')

plt.scatter(data[data['Buy_Signal'] == 1].Date,
            data[data['Buy_Signal'] == 1]['Last trade price'],
            marker='^', color='green', label='Buy Signal', alpha=1)

plt.scatter(data[data['Sell_Signal'] == 1].Date,
            data[data['Sell_Signal'] == 1]['Last trade price'],
            marker='v', color='red', label='Sell Signal', alpha=1)

plt.legend()
plt.title('Stock Price with Buy/Sell Signals')
plt.xlabel('Date')
plt.ylabel('Price')
plt.show()

import pandas as pd

data = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv')
print(data.columns)

plt.plot(data.index, data['Last trade price'], label='Price', color='black')
plt.plot(data.index, data['SMA_20'], label='SMA 20', color='blue')
plt.plot(data.index, data['EMA_20'], label='EMA 20', color='red')

plt.scatter(data.index[data['Buy_Signal'] == 1],
            data[data['Buy_Signal'] == 1]['Last trade price'],
            marker='^', color='green', label='Buy Signal', alpha=1)

plt.scatter(data.index[data['Sell_Signal'] == 1],
            data[data['Sell_Signal'] == 1]['Last trade price'],
            marker='v', color='red', label='Sell Signal', alpha=1)

plt.legend()
plt.title('Stock Price with Buy/Sell Signals')
plt.xlabel('Index')
plt.ylabel('Price')
plt.show()

data = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv', parse_dates=['correct_column_name'])

plt.plot(data.index, data['Last trade price'], label='Price', color='black')
plt.plot(data.index, data['SMA_20'], label='SMA 20', color='blue')
plt.plot(data.index, data['EMA_20'], label='EMA 20', color='red')

plt.scatter(data.index[data['Buy_Signal'] == 1],
            data[data['Buy_Signal'] == 1]['Last trade price'],
            marker='^', color='green', label='Buy Signal', alpha=1)

plt.scatter(data.index[data['Sell_Signal'] == 1],
            data[data['Sell_Signal'] == 1]['Last trade price'],
            marker='v', color='red', label='Sell Signal', alpha=1)

plt.legend()
plt.title('Stock Price with Buy/Sell Signals')
plt.xlabel('Index')
plt.ylabel('Price')
plt.show()

data['SMA_20'] = data['Last trade price'].rolling(window=20).mean()

print(data.columns)
print(data.head())

data['SMA_20'].fillna(method='ffill', inplace=True)
data['SMA_20'].fillna(method='bfill', inplace=True)

plt.figure(figsize=(10, 6))
plt.plot(data['Date'], data['Last trade price'], label='Price', color='black')
plt.plot(data['Date'], data['SMA_20'], label='SMA 20', color='blue')

plt.scatter(data[data['Buy_Signal'] == 1].Date,
            data[data['Buy_Signal'] == 1]['Last trade price'],
            marker='^', color='green', label='Buy Signal', alpha=1)

plt.scatter(data[data['Sell_Signal'] == 1].Date,
            data[data['Sell_Signal'] == 1]['Last trade price'],
            marker='v', color='red', label='Sell Signal', alpha=1)

plt.legend()
plt.title('Stock Price with Buy/Sell Signals')
plt.xlabel('Date')
plt.ylabel('Price')
plt.xticks(rotation=45)
plt.show()

plt.figure(figsize=(10, 6))
plt.plot(data['Avg. Price'], data['SMA_20'], label='SMA 20', color='blue')

plt.scatter(data[data['Buy_Signal'] == 1].index,
            data[data['Buy_Signal'] == 1]['Last trade price'],
            marker='^', color='green', label='Buy Signal', alpha=1)

plt.scatter(data[data['Sell_Signal'] == 1].index,
            data[data['Sell_Signal'] == 1]['Last trade price'],
            marker='v', color='red', label='Sell Signal', alpha=1)

plt.legend()
plt.title('Stock Price with Buy/Sell Signals')
plt.xlabel('Date')
plt.ylabel('Price')
plt.xticks(rotation=45)
plt.show()

print(data.columns)

import pandas as pd
import numpy as np
import ta
import matplotlib.pyplot as plt

data = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv')

data['SMA_20'] = data['Last trade price'].rolling(window=20).mean()
data['EMA_20'] = data['Last trade price'].ewm(span=20, adjust=False).mean()

data['RSI'] = ta.momentum.RSIIndicator(data['Last trade price'], window=14).rsi()

data['MACD'] = ta.trend.MACD(data['Last trade price']).macd()
data['MACD_signal'] = ta.trend.MACD(data['Last trade price']).macd_signal()

data['Buy_Signal'] = np.where(data['Last trade price'] > data['SMA_20'], 1, 0)
data['Sell_Signal'] = np.where(data['Last trade price'] < data['SMA_20'], 1, 0)

plt.figure(figsize=(10, 6))
plt.plot(data.index, data['Last trade price'], label='Price', color='black')
plt.plot(data.index, data['SMA_20'], label='SMA 20', color='blue')
plt.plot(data.index, data['EMA_20'], label='EMA 20', color='red')

plt.scatter(data[data['Buy_Signal'] == 1].index,
            data[data['Buy_Signal'] == 1]['Last trade price'],
            marker='^', color='green', label='Buy Signal', alpha=1)

plt.scatter(data[data['Sell_Signal'] == 1].index,
            data[data['Sell_Signal'] == 1]['Last trade price'],
            marker='v', color='red', label='Sell Signal', alpha=1)

plt.legend()
plt.title('Stock Price with Buy/Sell Signals')
plt.xlabel('Index')
plt.ylabel('Price')
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import ta

df = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv', parse_dates=['Date'])

df['RSI'] = ta.momentum.RSIIndicator(df['Last trade price'], window=14).rsi()

macd = ta.trend.MACD(df['Last trade price'])
df['MACD'] = macd.macd()
df['MACD_signal'] = macd.macd_signal()

stochastic = ta.momentum.StochasticOscillator(df['Last trade price'], df['Min'], df['Max'], window=14)
df['Stochastic'] = stochastic.stoch()

plt.figure(figsize=(10, 6))
plt.plot(df['Date'], df['Last trade price'], label='Price', color='black')
plt.plot(df['Date'], df['RSI'], label='RSI (14)', color='blue')
plt.plot(df['Date'], df['MACD'], label='MACD', color='green')
plt.plot(df['Date'], df['MACD_signal'], label='MACD Signal', color='red')
plt.plot(df['Date'], df['Stochastic'], label='Stochastic Oscillator', color='purple')
plt.legend()
plt.show()

import pandas as pd

df = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv')

print(df.columns)

import pandas as pd

df = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv')

print(df.head())

df['Date'] = pd.date_range(start='2020-01-01', periods=len(df), freq='D')

df['Date'] = pd.to_datetime(df['Date'])

print(df.head())

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import ta

df = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv', parse_dates=['Date'])

df['RSI'] = ta.momentum.RSIIndicator(df['Last trade price'], window=14).rsi()

macd = ta.trend.MACD(df['Last trade price'])
df['MACD'] = macd.macd()
df['MACD_signal'] = macd.macd_signal()

stochastic = ta.momentum.StochasticOscillator(df['Last trade price'], df['Min'], df['Max'], window=14)
df['Stochastic'] = stochastic.stoch()

plt.figure(figsize=(10, 6))
plt.plot(df['Date'], df['Last trade price'], label='Price', color='black')
plt.plot(df['Date'], df['RSI'], label='RSI (14)', color='blue')
plt.plot(df['Date'], df['MACD'], label='MACD', color='green')
plt.plot(df['Date'], df['MACD_signal'], label='MACD Signal', color='red')
plt.plot(df['Date'], df['Stochastic'], label='Stochastic Oscillator', color='purple')
plt.legend()
plt.show()

df = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv', parse_dates=['Date'])

print(df.columns)

df.columns = df.columns.str.strip()
print(df.columns)

df = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv')

df.columns = df.columns.str.strip()

df['Date'] = pd.to_datetime(df['Date'], errors='coerce')

print(df['Date'].head())

df.rename(columns={'<incorrect_column_name>': 'Date'}, inplace=True)

print(df.columns)

df = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv')

print(df.columns)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import ta

df = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv', parse_dates=['Date'])

df['RSI'] = ta.momentum.RSIIndicator(df['Last trade price'], window=14).rsi()

macd = ta.trend.MACD(df['Last trade price'])
df['MACD'] = macd.macd()
df['MACD_signal'] = macd.macd_signal()

stochastic = ta.momentum.StochasticOscillator(df['Last trade price'], df['Min'], df['Max'], window=14)
df['Stochastic'] = stochastic.stoch()

plt.figure(figsize=(10, 6))
plt.plot(df['Date'], df['Last trade price'], label='Price', color='black')
plt.plot(df['Date'], df['RSI'], label='RSI (14)', color='blue')
plt.plot(df['Date'], df['MACD'], label='MACD', color='green')
plt.plot(df['Date'], df['MACD_signal'], label='MACD Signal', color='red')
plt.plot(df['Date'], df['Stochastic'], label='Stochastic Oscillator', color='purple')
plt.legend()
plt.show()

import pandas as pd

df = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv')

start_date = pd.to_datetime('2020-01-01')
date_range = pd.date_range(start=start_date, periods=len(df), freq='D')

df['Date'] = date_range

print(df.head())

import pandas as pd
import numpy as np

df = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv')

df.columns = df.columns.str.strip()

df['Date'] = pd.to_datetime(df['Date'], errors='coerce')

print(df['Date'].head())

print(df.columns)

df.columns = df.columns.str.strip()

print(df.columns)

if 'Date' in df.columns:
    print("Date column found!")
else:
    print("Date column not found.")

for index, column in enumerate(df.columns):
    print(f"Index {index}: '{column}'")

df.rename(columns={'<old_name>': 'Date'}, inplace=True)

print(df.columns)

print(df.head())

df['Date'] = pd.date_range(start='2020-01-01', periods=len(df), freq='D')

import pandas as pd

df = pd.read_csv('/mse_data_cleaned_no_zeros_negatives_and_invalid_columns.csv')

df['Date'] = pd.date_range(start='2020-01-01', periods=len(df), freq='D')

print(df.head())

df['Price Change'] = df['Last trade price'].diff()

df['Gain'] = df['Price Change'].where(df['Price Change'] > 0, 0)
df['Loss'] = -df['Price Change'].where(df['Price Change'] < 0, 0)

df['Avg Gain'] = df['Gain'].rolling(window=14).mean()
df['Avg Loss'] = df['Loss'].rolling(window=14).mean()

df['RS'] = df['Avg Gain'] / df['Avg Loss']

df['RSI'] = 100 - (100 / (1 + df['RS']))

print(df[['Date', 'RSI']].tail())

overbought = df[df['RSI'] > 70]
oversold = df[df['RSI'] < 30]

print("Overbought Dates (RSI > 70):")
print(overbought[['Date', 'RSI']])

print("\nOversold Dates (RSI < 30):")
print(oversold[['Date', 'RSI']])

plt.figure(figsize=(10, 6))
plt.plot(df['Date'], df['RSI'], label='14-Day RSI')
plt.axhline(70, color='red', linestyle='--', label='Overbought (70)')
plt.axhline(30, color='green', linestyle='--', label='Oversold (30)')

plt.scatter(overbought['Date'], overbought['RSI'], color='red', label='Overbought', zorder=5)
plt.scatter(oversold['Date'], oversold['RSI'], color='green', label='Oversold', zorder=5)

plt.title('14-Day RSI')
plt.xlabel('Date')
plt.ylabel('RSI')
plt.legend()
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))

plt.plot(df['Date'], df['RSI'], label='14-Day RSI', color='blue', linewidth=2)

plt.axhline(70, color='red', linestyle='--', label='Overbought (70)')
plt.axhline(30, color='green', linestyle='--', label='Oversold (30)')

overbought = df[df['RSI'] > 70]
plt.scatter(overbought['Date'], overbought['RSI'], color='red', label='Overbought', zorder=5)

oversold = df[df['RSI'] < 30]
plt.scatter(oversold['Date'], oversold['RSI'], color='green', label='Oversold', zorder=5)

plt.title('14-Day RSI')
plt.xlabel('Date')
plt.ylabel('RSI')

plt.legend()

plt.xticks(rotation=45)

plt.tight_layout()

plt.show()

pip install vaderSentiment pandas requests beautifulsoup4

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

analyzer = SentimentIntensityAnalyzer()

def analyze_sentiment(text):
    sentiment_score = analyzer.polarity_scores(text)['compound']
    if sentiment_score >= 0.05:
        return 'Positive'
    elif sentiment_score <= -0.05:
        return 'Negative'
    else:
        return 'Neutral'

import requests
from bs4 import BeautifulSoup

def get_news(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')

    paragraphs = soup.find_all('p')
    news_content = " ".join([p.text for p in paragraphs])
    return news_content

news_url = 'https://www.mse.com.mk'
news_text = get_news(news_url)

sentiment = analyze_sentiment(news_text)
print("Sentiment:", sentiment)

import requests
from bs4 import BeautifulSoup

def get_news(url):
    response = requests.get(url, verify=False)
    soup = BeautifulSoup(response.text, 'html.parser')

    paragraphs = soup.find_all('p')
    news_content = " ".join([p.text for p in paragraphs])
    return news_content

news_url = 'https://www.mse.mk/daily/stats/symbolhistory/REPL?fbclid=PAY2xjawGbDElleHRuA2FlbQIxMAABprOfCGU-01uiZk2RriHFzXLGEXhqaSc-6G_y1BCYrFYHRJYrgYPIJzASeA_aem_c2NpwdUNW8BydaygLuxxkQ'
news_text = get_news(news_url)
print(news_text)

import yfinance as yf

def get_historical_data(stock_symbol):
    stock = yf.Ticker(stock_symbol)
    historical_data = stock.history(period="10y")

    print(historical_data)

get_historical_data('TSLA')

import yfinance as yf
import pandas as pd

def get_historical_data(stock_symbol):
    stock = yf.Ticker(stock_symbol)
    historical_data = stock.history(period="10y")
    print(historical_data.head())

    historical_data.to_csv(f"{stock_symbol}_historical_data.csv")

    return historical_data

data = get_historical_data('TSLA')

import ta

def calculate_technical_indicators(data):
    data['RSI'] = ta.momentum.RSIIndicator(data['Close'], window=14).rsi()

    data['SMA_50'] = data['Close'].rolling(window=50).mean()
    data['SMA_200'] = data['Close'].rolling(window=200).mean()

    data['EMA_50'] = data['Close'].ewm(span=50, adjust=False).mean()

    print(data[['Close', 'RSI', 'SMA_50', 'SMA_200', 'EMA_50']].tail())

    return data

data_with_indicators = calculate_technical_indicators(data)

def generate_trade_signals(data):
    data['Signal'] = 0

    data['Signal'][data['Close'] > data['SMA_50']] = 1
    data['Signal'][data['Close'] < data['SMA_50']] = -1

    print(data[['Close', 'SMA_50', 'Signal']].tail())
    return data

data_with_signals = generate_trade_signals(data_with_indicators)

from textblob import TextBlob

def analyze_sentiment(news):
    sentiment_scores = []

    for article in news:
        blob = TextBlob(article)
        sentiment_scores.append(blob.sentiment.polarity)

    return sentiment_scores

news_articles = [
    "Tesla stock soars after strong earnings report.",
    "Tesla faces challenges as production delays continue."
]
sentiment_scores = analyze_sentiment(news_articles)

print(sentiment_scores)

from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

def preprocess_for_lstm(data):
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled_data = scaler.fit_transform(data[['Close']])

    X = []
    y = []

    for i in range(60, len(scaled_data)):
        X.append(scaled_data[i-60:i, 0])
        y.append(scaled_data[i, 0])

    X = np.array(X)
    y = np.array(y)

    X = np.reshape(X, (X.shape[0], X.shape[1], 1))

    return X, y, scaler

def create_lstm_model():
    model = Sequential()
    model.add(LSTM(units=50, return_sequences=True, input_shape=(60, 1)))
    model.add(LSTM(units=50, return_sequences=False))
    model.add(Dense(units=1))
    model.compile(optimizer='adam', loss='mean_squared_error')

    return model

def train_lstm_model(X, y):
    model = create_lstm_model()
    model.fit(X, y, epochs=10, batch_size=32)
    return model

X, y, scaler = preprocess_for_lstm(data)
lstm_model = train_lstm_model(X, y)

import numpy as np
import matplotlib.pyplot as plt

def make_predictions(model, X_test, scaler):
    predicted_stock_price = model.predict(X_test)

    predicted_stock_price = scaler.inverse_transform(predicted_stock_price)

    return predicted_stock_price

train_size = int(len(data) * 0.8)
train_data = data[:train_size]
test_data = data[train_size:]

X_test, y_test, _ = preprocess_for_lstm(test_data)

predicted_prices = make_predictions(lstm_model, X_test, scaler)

plt.figure(figsize=(10,6))
plt.plot(test_data.index[-len(predicted_prices):], test_data['Close'].iloc[-len(predicted_prices):], color='blue', label='Actual Price')
plt.plot(test_data.index[-len(predicted_prices):], predicted_prices, color='red', label='Predicted Price')
plt.title('Stock Price Prediction')
plt.xlabel('Date')
plt.ylabel('Price')
plt.legend()
plt.show()

from sklearn.metrics import mean_squared_error, mean_absolute_error

def evaluate_model(y_test, predicted_prices):
    mse = mean_squared_error(y_test, predicted_prices)
    mae = mean_absolute_error(y_test, predicted_prices)
    print(f'Mean Squared Error (MSE): {mse}')
    print(f'Mean Absolute Error (MAE): {mae}')

evaluate_model(y_test, predicted_prices)

residuals = predicted_prices - y_test
plt.figure(figsize=(10,6))
plt.plot(test_data.index[-len(predicted_prices):], residuals, color='green')
plt.title('Residuals of Predictions')
plt.xlabel('Date')
plt.ylabel('Residual (Predicted - Actual)')
plt.show()

pip install ta

import pandas as pd
import ta

df['SMA_10'] = df['Close'].rolling(window=10).mean()
df['EMA_10'] = df['Close'].ewm(span=10, adjust=False).mean()

df['RSI'] = ta.momentum.RSIIndicator(df['Close'], window=14).rsi()
df['MACD'] = ta.trend.MACD(df['Close']).macd()
df['Stochastic'] = ta.momentum.StochasticOscillator(df['High'], df['Low'], df['Close'], window=14).stoch()

df['ADX'] = ta.trend.ADXIndicator(df['High'], df['Low'], df['Close'], window=14).adx()
df['MFI'] = ta.volume.MFIIndicator(df['High'], df['Low'], df['Close'], df['Volume'], window=14).money_flow_index()
df['CCI'] = ta.trend.CCIIndicator(df['High'], df['Low'], df['Close'], window=14).cci()

print(df.columns)

df['SMA_10'] = df['Last trade price'].rolling(window=10).mean()
df['EMA_10'] = df['Last trade price'].ewm(span=10, adjust=False).mean()

df['RSI'] = ta.momentum.RSIIndicator(df['Last trade price'], window=14).rsi()
df['MACD'] = ta.trend.MACD(df['Last trade price']).macd()
df['Stochastic'] = ta.momentum.StochasticOscillator(df['High'], df['Low'], df['Last trade price'], window=14).stoch()

df['ADX'] = ta.trend.ADXIndicator(df['High'], df['Low'], df['Last trade price'], window=14).adx()
df['MFI'] = ta.volume.MFIIndicator(df['High'], df['Low'], df['Last trade price'], df['Volume'], window=14).money_flow_index()
df['CCI'] = ta.trend.CCIIndicator(df['High'], df['Low'], df['Last trade price'], window=14).cci()

df['SMA_10'] = df['Last trade price'].rolling(window=10).mean()
df['EMA_10'] = df['Last trade price'].ewm(span=10, adjust=False).mean()

# Oscillators
df['RSI'] = ta.momentum.RSIIndicator(df['Last trade price'], window=14).rsi()
df['MACD'] = ta.trend.MACD(df['Last trade price']).macd()
df['Stochastic'] = ta.momentum.StochasticOscillator(df['Max'], df['Min'], df['Last trade price'], window=14).stoch()

df['ADX'] = ta.trend.ADXIndicator(df['Max'], df['Min'], df['Last trade price'], window=14).adx()
df['MFI'] = ta.volume.MFIIndicator(df['Max'], df['Min'], df['Last trade price'], df['Volume'], window=14).money_flow_index()
df['CCI'] = ta.trend.CCIIndicator(df['Max'], df['Min'], df['Last trade price'], window=14).cci()

df['Signal'] = 0
df.loc[df['RSI'] < 30, 'Signal'] = 1
df.loc[df['RSI'] > 70, 'Signal'] = -1

df['Signal_1_day'] = df['Signal'].shift(0)
df['Signal_1_week'] = df['Signal'].rolling(window=7).mean()
df['Signal_1_month'] = df['Signal'].rolling(window=30).mean()

pip install textblob

from textblob import TextBlob
import requests
from bs4 import BeautifulSoup

def get_news_from_url(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    headlines = soup.find_all('h2')
    return [headline.text for headline in headlines]

news_articles = get_news_from_url('https://www.mse.mk/daily/stats/symbolhistory/REPL?fbclid=PAY2xjawGbDElleHRuA2FlbQIxMAABprOfCGU-01uiZk2RriHFzXLGEXhqaSc-6G_y1BCYrFYHRJYrgYPIJzASeA_aem_c2NpwdUNW8BydaygLuxxkQ')  # Replace with real news URL

def analyze_sentiment(text):
    analysis = TextBlob(text)

    return analysis.sentiment.polarity

sentiments = [analyze_sentiment(article) for article in news_articles]

recommendations = ['Buy' if sentiment > 0 else 'Sell' for sentiment in sentiments]

df['News_Sentiment'] = sum(sentiments) / len(sentiments)
df['Final_Signal'] = df['Signal'] * (df['News_Sentiment'] > 0).astype(int)

if len(sentiments) > 0:
    df['News_Sentiment'] = sum(sentiments) / len(sentiments)
else:
    df['News_Sentiment'] = 0

df['News_Sentiment'] = sum(sentiments) / len(sentiments)
df['Final_Signal'] = df['Signal'] * (df['News_Sentiment'] > 0).astype(int)

print(sentiments)
if len(sentiments) > 0:
    df['News_Sentiment'] = sum(sentiments) / len(sentiments)
else:
    df['News_Sentiment'] = 0

from textblob import TextBlob

sentiment = TextBlob(news_article).sentiment.polarity
sentiments.append(sentiment)

news_article = "The stock market is doing well today with rising prices and high volume."

from textblob import TextBlob

# List of sample news articles
news_articles = [
    "The stock market is doing well today with rising prices.",
    "The market is facing challenges due to uncertain economic conditions.",
    "New technology is boosting stocks in the tech industry."
]

sentiments = []

for news_article in news_articles:
    sentiment = TextBlob(news_article).sentiment.polarity
    sentiments.append(sentiment)

print(sentiments)

news_articles = [
    "The stock market is doing well today with rising prices.",
    "",
    "The market is facing challenges due to uncertain economic conditions."
]

sentiments = []

for news_article in news_articles:
    if news_article.strip():
        sentiment = TextBlob(news_article).sentiment.polarity
        sentiments.append(sentiment)

print(sentiments)

if sentiments:
    avg_sentiment = sum(sentiments) / len(sentiments)
    print(f"Average Sentiment: {avg_sentiment}")
else:
    print("No sentiments to calculate.")

if sentiments:
    df['News_Sentiment'] = sum(sentiments) / len(sentiments)
else:
    df['News_Sentiment'] = 0

df['Final_Signal'] = df['Signal'] * (df['News_Sentiment'] > 0).astype(int)

df['News_Sentiment'] = sum(sentiments) / len(sentiments)
df['Final_Signal'] = df['Signal'] * (df['News_Sentiment'] > 0).astype(int)

from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout
import numpy as np

X = df[['Last trade price']].values
X = X.reshape((X.shape[0], 1, X.shape[1]))

train_size = int(len(X) * 0.7)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = df['Last trade price'][:train_size], df['Last trade price'][train_size:]

model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(units=1))

model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X_train, y_train, epochs=10, batch_size=32)

predictions = model.predict(X_test)

from sklearn.metrics import mean_squared_error, mean_absolute_error
mse = mean_squared_error(y_test, predictions)
mae = mean_absolute_error(y_test, predictions)

print(f'Mean Squared Error (MSE): {mse}')
print(f'Mean Absolute Error (MAE): {mae}')

from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error

df['Last trade price'] = df['Last trade price'].astype(float)

scaler = MinMaxScaler(feature_range=(0, 1))
df['Scaled_Price'] = scaler.fit_transform(df[['Last trade price']])

X = df[['Scaled_Price']].values
X = X.reshape((X.shape[0], 1, X.shape[1]))

train_size = int(len(X) * 0.7)
X_train, X_test = X[:train_size], X[train_size:]
y_train, y_test = df['Scaled_Price'][:train_size], df['Scaled_Price'][train_size:]

model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(units=1))

model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X_train, y_train, epochs=50, batch_size=32)

predictions = model.predict(X_test)

predictions = scaler.inverse_transform(predictions)
y_test_actual = scaler.inverse_transform(y_test.reshape(-1, 1))

mse = mean_squared_error(y_test_actual, predictions)
mae = mean_absolute_error(y_test_actual, predictions)

print(f'Mean Squared Error (MSE): {mse}')
print(f'Mean Absolute Error (MAE): {mae}')

predictions = scaler.inverse_transform(predictions)

y_test_actual = scaler.inverse_transform(np.array(y_test).reshape(-1, 1))

mse = mean_squared_error(y_test_actual, predictions)
mae = mean_absolute_error(y_test_actual, predictions)

print(f'Mean Squared Error (MSE): {mse}')
print(f'Mean Absolute Error (MAE): {mae}')

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.plot(y_test_actual, label='Actual', color='blue')
plt.plot(predictions, label='Predicted', color='red')
plt.title('Actual vs Predicted')
plt.xlabel('Time')
plt.ylabel('Price')
plt.legend()
plt.show()

plt.figure(figsize=(10, 6))
plt.plot(y_test_actual, label='Actual', color='blue')
plt.plot(predictions, label='Predicted', color='red')
plt.title('Actual vs Predicted')
plt.xlabel('Time')
plt.ylabel('Price')
plt.legend()
plt.show()

df['SMA'] = df['Last trade price'].rolling(window=30).mean()

df['EMA'] = df['Last trade price'].ewm(span=30, adjust=False).mean()

import ta
df['RSI'] = ta.momentum.RSIIndicator(df['Last trade price']).rsi()
df['MACD'] = ta.trend.MACD(df['Last trade price']).macd()

import matplotlib.pyplot as plt
plt.figure(figsize=(12, 6))
plt.plot(df['Last trade price'], label='Stock Price')
plt.plot(df['SMA'], label='SMA')
plt.plot(df['EMA'], label='EMA')
plt.legend()
plt.show()

from textblob import TextBlob
def sentiment_analysis(text):
    analysis = TextBlob(text)
    return analysis.sentiment.polarity

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(df[['Last trade price']], df['Last trade price'], test_size=0.3, shuffle=False)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))
model.add(LSTM(units=50, return_sequences=False))
model.add(Dense(units=1))
model.compile(optimizer='adam', loss='mean_squared_error')
model.fit(X_train, y_train, epochs=10, batch_size=32)

y_pred = model.predict(X_test)

from sklearn.metrics import mean_squared_error
mse = mean_squared_error(y_test, y_pred)
print(f'Mean Squared Error: {mse}')

plt.figure(figsize=(12, 6))
plt.plot(y_test, label='Actual Prices')
plt.plot(y_pred, label='Predicted Prices')
plt.legend()
plt.show()